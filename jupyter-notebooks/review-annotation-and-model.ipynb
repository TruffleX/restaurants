{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "16.030\t0.667\t0.143\t0.235\n",
      "13.725\t0.727\t0.286\t0.410\n",
      "8.718\t0.800\t0.429\t0.558\n",
      "7.127\t0.556\t0.357\t0.435\n",
      "6.015\t0.579\t0.393\t0.468\n",
      "5.484\t0.476\t0.357\t0.408\n",
      "3.525\t0.500\t0.321\t0.391\n",
      "2.962\t0.533\t0.286\t0.372\n",
      "3.474\t0.647\t0.393\t0.489\n",
      "2.919\t0.696\t0.571\t0.627\n",
      "1.850\t0.722\t0.464\t0.565\n",
      "1.899\t0.588\t0.357\t0.444\n",
      "Created blank 'en' model\n",
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "10.639\t0.933\t0.378\t0.538\n",
      "3.927\t0.955\t0.568\t0.712\n",
      "1.882\t0.962\t0.676\t0.794\n",
      "1.317\t0.960\t0.649\t0.774\n",
      "1.095\t0.958\t0.622\t0.754\n",
      "0.952\t0.958\t0.622\t0.754\n",
      "0.823\t0.960\t0.649\t0.774\n",
      "0.731\t0.960\t0.649\t0.774\n",
      "0.660\t0.960\t0.649\t0.774\n",
      "0.574\t0.960\t0.649\t0.774\n",
      "0.417\t0.960\t0.649\t0.774\n",
      "0.414\t0.960\t0.649\t0.774\n",
      "Created blank 'en' model\n",
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "17.731\t0.500\t0.000\t0.000\n",
      "13.936\t1.000\t0.194\t0.324\n",
      "10.558\t1.000\t0.226\t0.368\n",
      "7.502\t0.917\t0.355\t0.512\n",
      "4.496\t0.565\t0.419\t0.481\n",
      "2.459\t0.550\t0.355\t0.431\n",
      "2.045\t0.687\t0.355\t0.468\n",
      "1.819\t0.786\t0.355\t0.489\n",
      "2.140\t0.722\t0.419\t0.531\n",
      "1.831\t0.632\t0.387\t0.480\n",
      "1.286\t0.722\t0.419\t0.531\n",
      "0.839\t0.846\t0.355\t0.500\n"
     ]
    }
   ],
   "source": [
    "from db.dbclient import MongoClient\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TextModel:\n",
    "\n",
    "    \n",
    "    def __init__(self, model=None):\n",
    "        self.nlps = None\n",
    "    \n",
    "    def load_docs(self, field, test_size=.25):\n",
    "        query = { \"is_review\" : { \"$exists\" : True } }\n",
    "        client = MongoClient('articles').collection\n",
    "        results = list(client.find(query))\n",
    "    \n",
    "        texts, labels = [i.get(field, \"\") for i in results], [{\"is_review\": int(i['is_review'])} for i in results]        \n",
    "        return train_test_split(texts, labels, test_size=test_size)\n",
    "        \n",
    "    def train(self, model=None, field='content', test_size = .25, n_iter=12, n_texts=2000):\n",
    "        \n",
    "        if model is not None:\n",
    "            nlp = spacy.load(model)  # load existing spaCy model\n",
    "            print(\"Loaded model '%s'\" % model)\n",
    "        else:\n",
    "            nlp = spacy.load('en')\n",
    "            print(\"Created blank 'en' model\")\n",
    "            \n",
    "        if 'textcat' not in nlp.pipe_names:\n",
    "            self.textcat = nlp.create_pipe('textcat')\n",
    "            nlp.add_pipe(self.textcat, last=True)\n",
    "        # otherwise, get it, so we can add labels to it\n",
    "        else:\n",
    "            self.textcat = nlp.get_pipe('textcat')            \n",
    "            \n",
    "        # add label to text classifier\n",
    "        self.textcat.add_label('is_review')  \n",
    "        \n",
    "        train_texts, test_texts, train_labels, test_labels = self.load_docs(field, test_size=test_size)\n",
    "\n",
    "        # get names of other pipes to disable them during training\n",
    "        other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']           \n",
    "        train_data = list(zip(train_texts,\n",
    "                              [{'cats': i} for i in train_labels]))\n",
    "        \n",
    "        with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "            optimizer = nlp.begin_training()\n",
    "            print(\"Training the model...\")\n",
    "            print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "            for i in range(n_iter):\n",
    "                try:\n",
    "                    losses = {}\n",
    "                    # batch up the examples using spaCy's minibatch\n",
    "                    batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "                    for batch in batches:\n",
    "                        texts, annotations = zip(*batch)\n",
    "                        nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n",
    "                                   losses=losses)\n",
    "                    with self.textcat.model.use_params(optimizer.averages):\n",
    "                        # evaluate on the dev data split off in load_data()\n",
    "                        scores = self.evaluate(nlp.tokenizer, self.textcat, test_texts, test_labels)\n",
    "                    print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\n",
    "                          .format(losses['textcat'], scores['textcat_p'],\n",
    "                                  scores['textcat_r'], scores['textcat_f']))  \n",
    "                except KeyboardInterrupt:\n",
    "                    break\n",
    "                    \n",
    "        return nlp\n",
    "                    \n",
    "                \n",
    "    def evaluate(self, tokenizer, textcat, texts, cats):\n",
    "        docs = (tokenizer(text) for text in texts)\n",
    "        tp = 1e-8  # True positives\n",
    "        fp = 1e-8  # False positives\n",
    "        fn = 1e-8  # False negatives\n",
    "        tn = 1e-8  # True negatives\n",
    "        for i, doc in enumerate(textcat.pipe(docs)):\n",
    "            gold = cats[i]\n",
    "            for label, score in doc.cats.items():\n",
    "                if label not in gold:\n",
    "                    continue\n",
    "                if score >= 0.5 and gold[label] >= 0.5:\n",
    "                    tp += 1.\n",
    "                elif score >= 0.5 and gold[label] < 0.5:\n",
    "                    fp += 1.\n",
    "                elif score < 0.5 and gold[label] < 0.5:\n",
    "                    tn += 1\n",
    "                elif score < 0.5 and gold[label] >= 0.5:\n",
    "                    fn += 1\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "        return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}      \n",
    "    \n",
    "    def create_model(self):\n",
    "        nlps = {}\n",
    "        for field in ['title', 'content', 'meta_description']:\n",
    "            nlp = self.train(field=field)\n",
    "            nlps[field] = nlp\n",
    "        return nlps\n",
    "    \n",
    "    def build(self):\n",
    "        self.nlps = self.create_model()\n",
    "        \n",
    "        \n",
    "    def predict(self, document):\n",
    "        def fix(x):\n",
    "            if x is None:\n",
    "                return \" \"\n",
    "            if x == \"\":\n",
    "                return \" \"\n",
    "            return x\n",
    "        if self.nlps is None:\n",
    "            raise ValueError(\"call .build first\")\n",
    "        return np.mean([nlp(fix(document.get(key,\" \"))).cats['is_review'] for key, nlp in self.nlps.items()])  \n",
    "m = TextModel()\n",
    "m.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, document):\n",
    "    def fix(x):\n",
    "        if x is None:\n",
    "            return \" \"\n",
    "        if x == \"\":\n",
    "            return \" \"\n",
    "        return x\n",
    "    if model.nlps is None:\n",
    "        raise ValueError(\"call .build first\")\n",
    "    return np.mean([nlp(fix(document.get(key,\" \"))).cats['is_review'] for key, nlp in model.nlps.items()])        \n",
    "my_predict = partial(predict, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41526e8a9bd542d1bf1b0355b7aa09de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73362489d7fb4987974316593c29c5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Review', style=ButtonStyle()), Button(description='Not Review', style=ButtonStyle()), Button(description='Skip', style=ButtonStyle()))), VBox(children=(Textarea(value='', description='Probability(review)', layout=Layout(height='30px', width='20%')), Textarea(value='', description='title', layout=Layout(height='30px', width='80%')), Textarea(value='', description='meta_description', layout=Layout(height='80px', width='80%')), Textarea(value='', description='content', layout=Layout(height='200px', width='80%'))))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets.widgets import Textarea, HBox, VBox, Button, Layout\n",
    "from tqdm import tqdm_notebook\n",
    "from IPython.display import display\n",
    "from db.dbclient import MongoClient\n",
    "class Labeler:\n",
    "    def __init__(self, predict_function):\n",
    "        self.client = MongoClient('articles').collection\n",
    "        query = { \"is_review\" : { \"$exists\" : False } }\n",
    "        self.article_iter = self.client.find(query)\n",
    "        self.predict_function = predict_function\n",
    "        self.docs = self.order_annotations()\n",
    "        self.review = None\n",
    "        self.__init_display__()\n",
    "        self._next()      \n",
    "        \n",
    "    def label_docs(self):\n",
    "        reviews, labels = [], []\n",
    "        articles = list(self.article_iter)\n",
    "        N = len(articles)\n",
    "        for i in tqdm_notebook(articles, total=N):\n",
    "            try:\n",
    "                pred = self.predict_function(i)\n",
    "            except KeyError as e:\n",
    "                print(i.keys())\n",
    "                raise e\n",
    "            reviews.append(i)\n",
    "            labels.append(pred)\n",
    "        return reviews, labels\n",
    "    \n",
    "    def order_annotations(self):\n",
    "        docs, preds = self.label_docs()\n",
    "        certainties = abs(np.array([preds]) - .5)\n",
    "        uncertainty_idx = np.argsort(certainties)[::-1][0]\n",
    "        uncertainty_idx = [i for i in range(len(docs))]\n",
    "        results = zip([docs[i] for i in uncertainty_idx], [preds[i] for i in uncertainty_idx])\n",
    "        return (i for i in results)\n",
    "    \n",
    "    def _next(self):\n",
    "        self.review, prob = next(self.docs)\n",
    "        self.content.value = self.review.get('content', \" \")\n",
    "        self.title.value = self.review.get('title', \" \")\n",
    "        self.meta_description.value = self.review.get('meta_description', \" \")\n",
    "        self.prob.value = str(prob)\n",
    "        \n",
    "    def __init_display__(self):\n",
    "        self.prob = Textarea(description='Probability(review)', layout=Layout(width='20%', height='30px'))\n",
    "        self.content = Textarea(description='content', layout=Layout(width='80%', height='200px'))\n",
    "        self.title = Textarea(description='title', layout=Layout(width='80%', height='30px'))      \n",
    "        self.meta_description = Textarea(description='meta_description', layout=Layout(width='80%', height='80px'))\n",
    "        self.yes = Button(description='Review')\n",
    "        self.no = Button(description='Not Review')\n",
    "        self.skip = Button(description='Skip')\n",
    "        self.yes.on_click(self.review_true)\n",
    "        self.no.on_click(self.review_false)\n",
    "        self.skip.on_click(self.review_skip)\n",
    "        self.button_box = HBox([self.yes, self.no, self.skip])\n",
    "        self.text_box = VBox([self.prob, self.title, self.meta_description, self.content])\n",
    "        self.widget = VBox([self.button_box, self.text_box])\n",
    "        display(self.widget)\n",
    "        \n",
    "    def _submit_current(self):\n",
    "        self.client.find_one_and_replace({'_id': self.review['_id']}, self.review)\n",
    "\n",
    "    def review_true(self, b):\n",
    "        self.review['is_review'] = True\n",
    "        self._submit_current()\n",
    "        self._next()\n",
    "        \n",
    "    def review_false(self, b):\n",
    "        self.review['is_review'] = False\n",
    "        self._submit_current()\n",
    "        self._next()\n",
    "        \n",
    "    def review_skip(self, b):\n",
    "        self._next()\n",
    "        \n",
    "l = Labeler(my_predict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
